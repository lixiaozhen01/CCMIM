# Model structure configuration for CCMIM (Concrete Crack Mamba-in-Mamba)
model:
  type: "ccmim"  # Core model framework
  num_classes: 1  # Number of defect classes (focus on crack detection)
  
  # Configuration for Mamba-In-Mamba (MiM) module
  mim:
    hidden_dim: 256  # Hidden state dimension for MiM block (matches intermediate feature channels)
    num_layers: 4    # Number of MiM layers in backbone
    inner_mamba_dim: 128  # Hidden dimension for inner Mamba (local feature parsing)
    outer_mamba_dim: 256  # Hidden dimension for outer Mamba (global context capture)
    kernel_size: 3   # Convolution kernel size in MiM feature fusion
  
  # Configuration for Dynamic Dual Fusion (DDF) module
  ddf:
    in_channels: 256  # Input feature channel number (consistent with MiM output)
    eca_kernel_size: 3  # Kernel size for Enhanced Channel Attention (ECA)
    dynamic_filter_size: 3  # Kernel size for Dynamic Filter (DF)
    fusion_ratio: 0.5  # Weight ratio for dual-feature fusion (channel + spatial)
  
  # Configuration for Sparse Pyramid Transformer (SPT) module
  spt:
    token_levels: 3  # Number of coarse-to-fine token selection levels
    num_heads: 4     # Number of attention heads in multi-head self-attention (MHA)
    sparse_ratio: 0.6  # Ratio of sparse tokens retained (balances computation and accuracy)
    pyramid_scales: [4, 2, 1]  # Feature map scales for pyramid sparse attention (PSA)
  
  # Detection head configuration
  head:
    out_channels: 256  # Input channel number for detection head
    num_conv_layers: 2 # Number of convolution layers in detection head
    bbox_reg_weight: 5.0  # Weight for bounding box regression loss